# Afterlight v.0.2 alfa MVP

Цифровые завещания и передача важных данных «на случай X». Afterlight помогает заранее упорядочить доступы, инструкции и файлы в **сейфах**, назначить **получателей** и **верификаторов**, а также определить **события-триггеры**, при которых информация будет раскрыта нужным людям.


---

## Описание
Afterlight — это минималистичный backend‑сервис для управления цифровым наследием. Основные идеи:

- **Сейф (Safe)** — логический контейнер, в котором владелец концентрирует важные материалы.
- **Блок (Block)** — сущность внутри сейфа: текст/ссылка/метаданные файла. Для отдельных блоков можно включить **публичную ссылку** (поделиться конкретным элементом вне события выдачи).
- **Получатель (Recipient)** — человек, которому будут переданы блоки при наступлении события.
- **Верификатор (Verifier)** — человек, который подтверждает событие. На уровне сейфа задаётся **один Primary Verifier** (обязательный участник подтверждения).
- **Событие (Event)** — факт, который запускает процесс выдачи (например, «потеря связи», «подтверждение смерти», «ручной запуск»). Событие переводит сейф в состояние подготовки к выдаче, собираются подтверждения от верификаторов.
- **Политика выдачи** — привязка «какие блоки — каким получателям — при каком событии». В MVP это простая связь блоков и получателей; далее планируются задержки (cooldown), m-of-n подтверждения и т. п.

Сервис ориентирован на «backend‑first»: API описано в OpenAPI/Swagger, есть Docker‑образ и манифесты для Kubernetes/k3s. В качестве БД используется PostgreSQL через Prisma.

---

## Реализовано в MVP
- **Модель данных и миграции** (Prisma): сейфы, блоки, получатели, верификаторы, события, привязки блок ↔ получатель.
- **REST API** c **Swagger UI** (`/docs`) и health‑эндпоинтом (`/healthz`).
- **CRUD для сейфов и блоков**: создание, обновление, пометка блока как публичного (получение публичной ссылки).
- **Получатели и верификаторы**: добавление/связывание с сейфом. На сейфе — **ровно один Primary Verifier**.
- **События**: регистрация события по сейфу и перевод сейфа в состояние «ожидание подтверждений».
- **Простая политика выдачи**: привязка блоков к получателям; при подтверждённом событии элементы переходят в состояние «готово к выдаче» (без реальной рассылки в MVP).
- **Конфигурация через ENV**: `DATABASE_URL`, `NODE_ENV`, `PORT`, `DEFAULT_DEBUG_USER` (для локальной отладки).
- **Контейнеризация**: готовые Docker‑файлы, манифесты под Kubernetes/k3s.
- **Логи и базовая наблюдаемость**: структурированные логи приложений, probes для k8s.

Ограничения MVP:
- Нет полноценной аутентификации и ролей (используется debug‑пользователь через ENV).
- Нет отправки e‑mail/уведомлений и нет хранения бинарных файлов (только метаданные/ссылки).
- Публичные блоки выдают содержимое по ссылке, но без тонкой политики доступа и TTL.

## Технологический стек
- **Backend:** NestJS (TypeScript), Prisma, PostgreSQL.
- **Frontend:** Next.js 14, React 18, Tailwind CSS, Framer Motion, lucide-react.
- **Инфраструктура:** Docker, Kubernetes/k3s, GitHub Actions, GHCR.

## Архитектура
Монорепозиторий состоит из двух приложений:
- `apps/api` — REST API на NestJS с Prisma и PostgreSQL, со Swagger UI и health‑пробами.
- `apps/web` — фронтенд на Next.js, предоставляет landing и административный интерфейс.
Оба сервиса упакованы в Docker‑образы и разворачиваются в Kubernetes.

## CI/CD
- `.github/workflows/ci.yml` — сборка и проверка API (npm ci, Prisma validate, Nest build).
- `.github/workflows/cd.yaml` — публикация Docker‑образов в GHCR и деплой на k3s.
- `.github/workflows/db-migrate.yml` и `db-seed.yml` — ручные миграции и заполнение БД.

## Деплой на k3s
1. Соберите и запушьте образы `afterlight-api` и `afterlight-web` (делает workflow `cd.yaml`).
2. На сервере k3s примените манифесты и секреты:
```bash
kubectl apply -f k8s/base/namespace.yaml
kubectl -n afterlight create secret generic api-secrets \
  --from-literal=DATABASE_URL='postgresql://user:pass@db:5432/afterlight?schema=public' \
  --from-literal=JWT_SECRET='please-change-me'
kubectl apply -f k8s/base/api-configmap.yaml
kubectl apply -f k8s/base/api-deployment.yaml
kubectl apply -f k8s/base/api-service.yaml
kubectl apply -f k8s/base/api-ingress.yaml
kubectl apply -f k8s/base/web-configmap.yaml
kubectl apply -f k8s/base/web-deployment.yaml
kubectl apply -f k8s/base/web-service.yaml
kubectl apply -f k8s/base/web-ingress.yaml
kubectl apply -f k8s/base/migrate-job.yaml
kubectl -n afterlight logs job/prisma-migrate -f
```
3. Проверка: `GET https://<host>/healthz` и `GET https://<host>/readyz`.

## Последние изменения
- Обновлён Dockerfile API: использование `npm ci` с lockfile.
- Добавлен middleware авторизации для `/adm`, конфигурация landing вынесена в ENV.
- Реализована поддержка `mk`-wrapped ключей и добавлены сервисные тесты.
- Проведён рефакторинг логирования и чистка временных файлов.
- Веб-интерфейс переработан: новый дизайн landing, иконки, выбор цветов и админ‑панель.
- Исправлено сохранение публичных ссылок и добавлены тесты их персистентности.

---

## Roadmap

### Фаза 1 — «Продуктовая готовность»
- **Аутентификация и роли**: JWT/сессии, владелец/верификатор/получатель.
- **Уведомления**: SMTP (e‑mail) + одноразовые/временные ссылки на выдачу.
- **Хранилище**: S3‑совместимое для файлов блоков, presigned URL, ограничение размера/типа.
- **Политики доступа**: базовые ACL на сейф/блок, аудит действий (кто/что/когда).
- **Rate limiting** и защита эндпоинтов.
- **Админ‑утилиты**: скрипты/CLI для обслуживания, экспорт/импорт данных.
- **Базовый веб‑интерфейс** (минимум для владельца, чтобы не ходить в Swagger).

### Фаза 2 — «Криптомодель и автоматика»
- **Клиентское шифрование** (WebCrypto), распределение ключей (m-of-n) для верификаторов.
- **Пороговые подтверждения**: m‑of‑n для события (не только Primary).
- **Heartbeat/проверки**: периодические запросы владельцу, задержка (cooldown) перед выдачей.
- **Webhooks/интеграции**: нотификация внешних систем о событиях/выдачах.
- **Политики хранения и «безопасное удаление»**: срок жизни, ретеншн, очистка.
- **Мультиязычность** и **биллинг** (подписки/лимиты).
